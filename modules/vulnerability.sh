#!/bin/bash
# ==============================================================================
# GHOST-FRAMEWORK - Vulnerability Scanning Module
# ==============================================================================
# File: modules/vulnerability.sh
# Description: Automated vulnerability detection with Nuclei, Dalfox, and SQLi
# License: MIT
# 
# This module handles the vulnerability scanning phase:
# - Nuclei template scanning (WAF-aware rate limiting)
# - Dalfox XSS detection
# - SQL injection pattern detection
# - Finding deduplication and severity classification
# ==============================================================================

# Severity colors for terminal output
declare -A SEVERITY_COLORS=(
    ["critical"]="\033[1;31m"   # Bold Red
    ["high"]="\033[0;31m"       # Red
    ["medium"]="\033[0;33m"     # Yellow
    ["low"]="\033[0;34m"        # Blue
    ["info"]="\033[0;32m"       # Green
)

# Finding counters
declare -A FINDING_COUNTS=(
    ["critical"]=0
    ["high"]=0
    ["medium"]=0
    ["low"]=0
    ["info"]=0
)

# ------------------------------------------------------------------------------
# reset_finding_counts()
# Reset the finding counters
# ------------------------------------------------------------------------------
reset_finding_counts() {
    for severity in "${!FINDING_COUNTS[@]}"; do
        FINDING_COUNTS[$severity]=0
    done
}

# ------------------------------------------------------------------------------
# increment_finding()
# Increment the counter for a severity level
# Arguments: $1 = Severity (critical/high/medium/low/info)
# ------------------------------------------------------------------------------
increment_finding() {
    local severity="${1,,}"  # Convert to lowercase
    if [ -n "${FINDING_COUNTS[$severity]+x}" ]; then
        FINDING_COUNTS[$severity]=$((FINDING_COUNTS[$severity] + 1))
    fi
}

# ------------------------------------------------------------------------------
# get_nuclei_options()
# Build Nuclei command options based on config and WAF status
# Returns: String of Nuclei options
# ------------------------------------------------------------------------------
get_nuclei_options() {
    local opts="-silent -nc"  # No color for parsing
    
    # Threads
    local threads="${NUCLEI_THREADS:-25}"
    if [ "${IS_WAF:-false}" = "true" ]; then
        # Reduce threads for WAF
        threads=$((threads / ${WAF_THREAD_REDUCTION:-4}))
        [ "$threads" -lt 1 ] && threads=1
    fi
    opts="$opts -c $threads"
    
    # Rate limit
    local rate="${NUCLEI_RATE_LIMIT:-150}"
    if [ "${IS_WAF:-false}" = "true" ]; then
        rate=$((rate / 3))
        [ "$rate" -lt 5 ] && rate=5
    fi
    opts="$opts -rl $rate"
    
    # Bulk size
    local bulk="${NUCLEI_BULK_SIZE:-25}"
    opts="$opts -bs $bulk"
    
    # Severity filter
    local severity="${NUCLEI_SEVERITY:-low,medium,high,critical}"
    opts="$opts -severity $severity"
    
    # Exclude tags 
    if [ -n "${NUCLEI_EXCLUDE_TAGS:-}" ]; then
        opts="$opts -etags $NUCLEI_EXCLUDE_TAGS"
    fi
    
    # Timeout settings
    opts="$opts -timeout 10"
    
    echo "$opts"
}

# ------------------------------------------------------------------------------
# run_nuclei_scan()
# Run Nuclei template scanning against targets
# Arguments: $1 = Input file (URLs), $2 = Output file
# Returns: 0 on success, 1 on failure
# ------------------------------------------------------------------------------
run_nuclei_scan() {
    local input_file="$1"
    local output_file="$2"
    
    print_section "Nuclei Vulnerability Scanning"
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        log_warn "No targets for Nuclei scan"
        return 1
    fi
    
    local target_count
    target_count=$(wc -l < "$input_file" | tr -d ' ')
    log_info "Scanning $target_count targets..."
    
    # Get options
    local nuclei_opts
    nuclei_opts=$(get_nuclei_options)
    
    if [ "${IS_WAF:-false}" = "true" ]; then
        log_warn "WAF detected - using reduced scan speed"
    fi
    
    log_debug "Nuclei options: $nuclei_opts"
    
    # Update templates if enabled
    if [ "${NUCLEI_TEMPLATES_UPDATE:-true}" = "true" ]; then
        log_info "Checking for template updates..."
        nuclei -update-templates -silent 2>/dev/null || true
    fi
    
    # Run Nuclei with JSON output for parsing
    local json_output="${output_file%.txt}.json"
    
    log_info "Starting Nuclei scan (this may take a while)..."
    
    if nuclei -l "$input_file" $nuclei_opts -je "$json_output" -o "$output_file" 2>/dev/null; then
        log_success "Nuclei scan completed"
        
        # Parse results and count by severity
        if [ -f "$json_output" ]; then
            parse_nuclei_results "$json_output"
        fi
        
        return 0
    else
        log_error "Nuclei scan failed"
        return 1
    fi
}

# ------------------------------------------------------------------------------
# parse_nuclei_results()
# Parse Nuclei JSON output and categorize findings
# Arguments: $1 = JSON output file
# ------------------------------------------------------------------------------
parse_nuclei_results() {
    local json_file="$1"
    
    if [ ! -f "$json_file" ] || [ ! -s "$json_file" ]; then
        return
    fi
    
    log_info "Parsing Nuclei results..."
    
    # Parse JSON and count by severity using jq
    if command -v jq &> /dev/null; then
        # Count each severity
        for severity in critical high medium low info; do
            local count
            count=$(jq -r "select(.info.severity == \"$severity\") | .info.severity" "$json_file" 2>/dev/null | wc -l | tr -d ' ')
            FINDING_COUNTS[$severity]=$((FINDING_COUNTS[$severity] + count))
        done
        
        # Display findings with color
        while IFS= read -r line; do
            local sev name matched
            sev=$(echo "$line" | jq -r '.info.severity' 2>/dev/null)
            name=$(echo "$line" | jq -r '.info.name' 2>/dev/null)
            matched=$(echo "$line" | jq -r '.matched-at' 2>/dev/null)
            
            if [ -n "$sev" ] && [ "$sev" != "null" ]; then
                local color="${SEVERITY_COLORS[$sev]:-\033[0m}"
                echo -e "${color}[${sev^^}]${COLOR_RESET:-\033[0m} $name - $matched"
                
                # Send notification for high/critical findings
                if [ "$sev" = "critical" ] || [ "$sev" = "high" ]; then
                    notify_finding "$sev" "$name" "$matched" "Nuclei detection" 2>/dev/null || true
                fi
            fi
        done < "$json_file"
    fi
}

# ------------------------------------------------------------------------------
# run_dalfox_scan()
# Run Dalfox XSS scanning against parameterized URLs
# Arguments: $1 = Input file (URLs with params), $2 = Output file
# Returns: 0 on success, 1 on failure
# ------------------------------------------------------------------------------
run_dalfox_scan() {
    local input_file="$1"
    local output_file="$2"
    
    print_section "Dalfox XSS Scanning"
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        log_warn "No parameterized URLs for XSS scan"
        return 1
    fi
    
    # Check if Dalfox is installed
    if ! command -v dalfox &> /dev/null; then
        log_error "Dalfox is not installed"
        return 1
    fi
    
    local target_count
    target_count=$(wc -l < "$input_file" | tr -d ' ')
    log_info "Scanning $target_count URLs for XSS..."
    
    # Build Dalfox options
    local dalfox_opts="pipe --silence"
    
    # Add threads
    local threads="${DALFOX_THREADS:-10}"
    if [ "${IS_WAF:-false}" = "true" ]; then
        threads=$((threads / 2))
        [ "$threads" -lt 1 ] && threads=1
    fi
    dalfox_opts="$dalfox_opts -w $threads"
    
    # Add timeout
    local timeout="${DALFOX_TIMEOUT:-10}"
    dalfox_opts="$dalfox_opts --timeout $timeout"
    
    # WAF evasion if enabled
    if [ "${DALFOX_WAF_EVASION:-true}" = "true" ]; then
        dalfox_opts="$dalfox_opts --waf-evasion"
    fi
    
    # Add delay for WAF
    if [ "${IS_WAF:-false}" = "true" ]; then
        dalfox_opts="$dalfox_opts --delay 1000"  # 1 second delay
        log_info "Added 1s delay for WAF evasion"
    fi
    
    log_info "Starting Dalfox scan..."
    
    if cat "$input_file" | dalfox $dalfox_opts -o "$output_file" 2>/dev/null; then
        local xss_count
        xss_count=$(wc -l < "$output_file" 2>/dev/null | tr -d ' ')
        
        if [ "$xss_count" -gt 0 ]; then
            log_critical "Found $xss_count potential XSS vulnerabilities!"
            FINDING_COUNTS["high"]=$((FINDING_COUNTS["high"] + xss_count))
            
            # Notify about XSS findings
            notify_finding "HIGH" "XSS Vulnerability" "$xss_count targets affected" "Dalfox detection" 2>/dev/null || true
        else
            log_info "No XSS vulnerabilities found"
        fi
        
        return 0
    else
        log_error "Dalfox scan failed"
        return 1
    fi
}

# ------------------------------------------------------------------------------
# run_sqli_detection()
# Basic SQL injection pattern detection
# Arguments: $1 = Input file (parameterized URLs), $2 = Output file
# Returns: 0 on success, 1 on failure
# ------------------------------------------------------------------------------
run_sqli_detection() {
    local input_file="$1"
    local output_file="$2"
    
    print_section "SQL Injection Detection"
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        log_warn "No parameterized URLs for SQLi detection"
        return 1
    fi
    
    log_info "Running SQLi pattern detection..."
    
    # First, use GF to find SQLi-suspect parameters if available
    local sqli_urls="${output_file%.txt}_candidates.txt"
    
    if command -v gf &> /dev/null; then
        cat "$input_file" | gf sqli > "$sqli_urls" 2>/dev/null || true
        local candidate_count
        candidate_count=$(wc -l < "$sqli_urls" 2>/dev/null | tr -d ' ')
        log_info "GF found $candidate_count SQLi candidate URLs"
    else
        cp "$input_file" "$sqli_urls"
    fi
    
    if [ ! -s "$sqli_urls" ]; then
        log_info "No SQLi candidates to test"
        return 0
    fi
    
    # Use qsreplace to inject test payloads if available
    if command -v qsreplace &> /dev/null; then
        log_info "Testing with SQLi error-based payloads..."
        
        local test_payloads="' \"  ) ' OR 1=1-- ' AND 1=1-- SLEEP(5)--"
        local positive_results="$output_file"
        : > "$positive_results"
        
        for payload in $test_payloads; do
            # Replace parameters with payload and test response
            while IFS= read -r url; do
                local test_url
                test_url=$(echo "$url" | qsreplace "$payload" 2>/dev/null)
                
                if [ -n "$test_url" ]; then
                    # Check for SQL error patterns in response
                    local response
                    response=$(curl -s -L --max-time 10 "$test_url" 2>/dev/null | head -c 50000)
                    
                    # Look for common SQL error messages
                    if echo "$response" | grep -qiE "(sql|mysql|sqlite|postgresql|oracle|syntax error|query|database|column|table|select|insert|update|delete)"; then
                        echo "$test_url" >> "$positive_results"
                        log_warn "Potential SQLi: $url"
                        increment_finding "high"
                    fi
                fi
            done < "$sqli_urls"
        done
        
        local sqli_count
        sqli_count=$(wc -l < "$positive_results" 2>/dev/null | tr -d ' ')
        
        if [ "$sqli_count" -gt 0 ]; then
            log_critical "Found $sqli_count potential SQLi vulnerabilities!"
            sort -u "$positive_results" > "${positive_results}.tmp" && mv "${positive_results}.tmp" "$positive_results"
            
            notify_finding "CRITICAL" "SQL Injection" "$sqli_count endpoints affected" "Pattern detection" 2>/dev/null || true
        else
            log_success "No obvious SQLi vulnerabilities found"
        fi
    else
        log_warn "qsreplace not available - skipping active SQLi testing"
        # Just copy candidates as potential SQLi targets
        cp "$sqli_urls" "$output_file"
    fi
    
    return 0
}

# ------------------------------------------------------------------------------
# deduplicate_findings()
# Remove duplicate findings based on URL and vulnerability type
# Arguments: $1 = Findings directory
# ------------------------------------------------------------------------------
deduplicate_findings() {
    local findings_dir="$1"
    
    log_info "Deduplicating findings..."
    
    # Deduplicate each findings file
    for file in "$findings_dir"/*.txt; do
        if [ -f "$file" ]; then
            sort -u "$file" > "${file}.tmp" && mv "${file}.tmp" "$file"
        fi
    done
    
    for file in "$findings_dir"/*.json; do
        if [ -f "$file" ] && command -v jq &> /dev/null; then
            # Deduplicate JSON by matched-at field
            jq -s 'unique_by(."matched-at")' "$file" > "${file}.tmp" 2>/dev/null && mv "${file}.tmp" "$file"
        fi
    done
}

# ------------------------------------------------------------------------------
# generate_vuln_report()
# Generate a summary report of the vulnerability scan phase
# Arguments: $1 = Workspace directory
# ------------------------------------------------------------------------------
generate_vuln_report() {
    local workspace="$1"
    local report_file="$workspace/vulnerability_summary.txt"
    local findings_dir="$workspace/findings"
    
    log_info "Generating vulnerability report..."
    
    {
        echo "═══════════════════════════════════════════════════════════"
        echo "        GHOST-FRAMEWORK - Vulnerability Summary"
        echo "═══════════════════════════════════════════════════════════"
        echo ""
        echo "Scan Date: $(date '+%Y-%m-%d %H:%M:%S')"
        echo "Target: ${TARGET_DOMAIN:-Unknown}"
        echo ""
        echo "───────────────────────────────────────────────────────────"
        echo "FINDINGS BY SEVERITY"
        echo "───────────────────────────────────────────────────────────"
        printf "%-15s %s\n" "CRITICAL:" "${FINDING_COUNTS[critical]:-0}"
        printf "%-15s %s\n" "HIGH:" "${FINDING_COUNTS[high]:-0}"
        printf "%-15s %s\n" "MEDIUM:" "${FINDING_COUNTS[medium]:-0}"
        printf "%-15s %s\n" "LOW:" "${FINDING_COUNTS[low]:-0}"
        printf "%-15s %s\n" "INFO:" "${FINDING_COUNTS[info]:-0}"
        echo ""
        
        local total=0
        for sev in "${!FINDING_COUNTS[@]}"; do
            total=$((total + FINDING_COUNTS[$sev]))
        done
        echo "TOTAL FINDINGS: $total"
        
        echo ""
        echo "───────────────────────────────────────────────────────────"
        echo "SCAN DETAILS"
        echo "───────────────────────────────────────────────────────────"
        
        # Nuclei results
        if [ -f "$findings_dir/nuclei_results.txt" ]; then
            echo "Nuclei Findings:     $(wc -l < "$findings_dir/nuclei_results.txt" | tr -d ' ')"
        fi
        
        # XSS results
        if [ -f "$findings_dir/xss_results.txt" ]; then
            echo "XSS Findings:        $(wc -l < "$findings_dir/xss_results.txt" | tr -d ' ')"
        fi
        
        # SQLi results  
        if [ -f "$findings_dir/sqli_results.txt" ]; then
            echo "SQLi Candidates:     $(wc -l < "$findings_dir/sqli_results.txt" | tr -d ' ')"
        fi
        
        echo ""
        echo "───────────────────────────────────────────────────────────"
        echo "WAF STATUS"
        echo "───────────────────────────────────────────────────────────"
        echo "WAF Detected:        ${IS_WAF:-false}"
        if [ "${IS_WAF:-false}" = "true" ]; then
            echo "WAF Provider:        ${WAF_PROVIDER:-Unknown}"
            echo "Scan Mode:           Adaptive (reduced speed)"
        fi
        
        echo ""
        echo "═══════════════════════════════════════════════════════════"
        
    } > "$report_file"
    
    log_success "Report saved to $report_file"
}

# ------------------------------------------------------------------------------
# run_ssrf_detection()
# Detect Server-Side Request Forgery vulnerabilities
# Arguments: $1 = Input file (URLs with params), $2 = Output file
# ------------------------------------------------------------------------------
run_ssrf_detection() {
    local input_file="$1"
    local output_file="$2"
    
    log_info "Checking for SSRF vulnerabilities..."
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        return 1
    fi
    
    # SSRF test payloads
    local ssrf_payloads=(
        "http://127.0.0.1"
        "http://localhost"
        "http://169.254.169.254/latest/meta-data/"
        "http://[::1]"
        "http://0.0.0.0"
        "http://0177.0.0.1"
        "http://2130706433"
    )
    
    # Find SSRF-prone parameters using GF if available
    local ssrf_urls
    if command -v gf &>/dev/null; then
        ssrf_urls=$(cat "$input_file" | gf ssrf 2>/dev/null | head -50)
    else
        # Look for common SSRF parameters
        ssrf_urls=$(grep -iE "(url=|uri=|path=|dest=|redirect=|return=|next=|site=|html=|data=|reference=|file=|load=)" "$input_file" | head -50)
    fi
    
    if [ -z "$ssrf_urls" ]; then
        log_info "No SSRF-prone parameters found"
        return 0
    fi
    
    local found=0
    
    while IFS= read -r url; do
        [ -z "$url" ] && continue
        
        for payload in "${ssrf_payloads[@]}"; do
            if command -v qsreplace &>/dev/null; then
                local test_url
                test_url=$(echo "$url" | qsreplace "$payload" 2>/dev/null)
                
                if [ -n "$test_url" ]; then
                    local response
                    response=$(curl -s -L --max-time 10 "$test_url" 2>/dev/null)
                    
                    # Check for AWS metadata or localhost indicators
                    if echo "$response" | grep -qiE "(ami-id|instance-id|localhost|127\.0\.0\.1|internal server error)"; then
                        echo "[SSRF] $test_url" >> "$output_file"
                        echo -e "\033[1;31m[CRITICAL]\033[0m Potential SSRF: $url"
                        found=$((found + 1))
                        increment_finding "critical"
                        break
                    fi
                fi
            fi
        done
        
        [ "${IS_WAF:-false}" = "true" ] && sleep 1 || sleep 0.2
        
    done <<< "$ssrf_urls"
    
    if [ "$found" -gt 0 ]; then
        log_critical "Found $found potential SSRF vulnerabilities!"
        notify_finding "CRITICAL" "SSRF Vulnerability" "$found endpoints" "SSRF detection" 2>/dev/null &
    else
        log_info "No SSRF vulnerabilities detected"
    fi
    
    return 0
}

# ------------------------------------------------------------------------------
# run_open_redirect_detection()
# Detect Open Redirect vulnerabilities
# Arguments: $1 = Input file (URLs with params), $2 = Output file
# ------------------------------------------------------------------------------
run_open_redirect_detection() {
    local input_file="$1"
    local output_file="$2"
    
    log_info "Checking for Open Redirect vulnerabilities..."
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        return 1
    fi
    
    # Redirect test payloads
    local redirect_payloads=(
        "https://evil.com"
        "//evil.com"
        "/\\evil.com"
        "https:evil.com"
        "//evil.com/%2f%2e%2e"
    )
    
    # Find redirect-prone parameters
    local redirect_urls
    if command -v gf &>/dev/null; then
        redirect_urls=$(cat "$input_file" | gf redirect 2>/dev/null | head -50)
    else
        redirect_urls=$(grep -iE "(redirect=|url=|return=|next=|goto=|rurl=|dest=|destination=|continue=|forward=)" "$input_file" | head -50)
    fi
    
    if [ -z "$redirect_urls" ]; then
        log_info "No redirect-prone parameters found"
        return 0
    fi
    
    local found=0
    
    while IFS= read -r url; do
        [ -z "$url" ] && continue
        
        for payload in "${redirect_payloads[@]}"; do
            if command -v qsreplace &>/dev/null; then
                local test_url
                test_url=$(echo "$url" | qsreplace "$payload" 2>/dev/null)
                
                if [ -n "$test_url" ]; then
                    local location
                    location=$(curl -s -I -L --max-time 10 --max-redirs 3 "$test_url" 2>/dev/null | grep -i "^location:" | tail -1)
                    
                    if echo "$location" | grep -qi "evil.com"; then
                        echo "[REDIRECT] $test_url" >> "$output_file"
                        echo -e "\033[0;33m[MEDIUM]\033[0m Open Redirect: $url"
                        found=$((found + 1))
                        increment_finding "medium"
                        break
                    fi
                fi
            fi
        done
        
        [ "${IS_WAF:-false}" = "true" ] && sleep 1 || sleep 0.2
        
    done <<< "$redirect_urls"
    
    if [ "$found" -gt 0 ]; then
        log_warn "Found $found Open Redirect vulnerabilities"
    else
        log_info "No Open Redirect vulnerabilities detected"
    fi
    
    return 0
}

# ------------------------------------------------------------------------------
# run_cors_check()
# Check for CORS misconfiguration
# Arguments: $1 = Input file (live hosts), $2 = Output file
# ------------------------------------------------------------------------------
run_cors_check() {
    local input_file="$1"
    local output_file="$2"
    
    log_info "Checking for CORS misconfiguration..."
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        return 1
    fi
    
    local found=0
    
    while IFS= read -r url; do
        [ -z "$url" ] && continue
        
        # Test with malicious origin
        local response
        response=$(curl -s -I -H "Origin: https://evil.com" --max-time 10 "$url" 2>/dev/null)
        
        local acao
        acao=$(echo "$response" | grep -i "Access-Control-Allow-Origin" | tr -d '\r')
        local acac
        acac=$(echo "$response" | grep -i "Access-Control-Allow-Credentials" | tr -d '\r')
        
        # Check for dangerous configurations
        if echo "$acao" | grep -qi "evil.com"; then
            if echo "$acac" | grep -qi "true"; then
                echo "[CORS-CRITICAL] $url - Origin reflected with credentials" >> "$output_file"
                echo -e "\033[1;31m[CRITICAL]\033[0m CORS with credentials: $url"
                increment_finding "critical"
                found=$((found + 1))
            else
                echo "[CORS-HIGH] $url - Origin reflected" >> "$output_file"
                echo -e "\033[0;31m[HIGH]\033[0m CORS misconfiguration: $url"
                increment_finding "high"
                found=$((found + 1))
            fi
        elif echo "$acao" | grep -qi "\*"; then
            echo "[CORS-MEDIUM] $url - Wildcard origin" >> "$output_file"
            echo -e "\033[0;33m[MEDIUM]\033[0m CORS wildcard: $url"
            increment_finding "medium"
            found=$((found + 1))
        fi
        
        [ "${IS_WAF:-false}" = "true" ] && sleep 1 || sleep 0.2
        
    done < <(head -50 "$input_file")
    
    if [ "$found" -gt 0 ]; then
        log_warn "Found $found CORS misconfigurations"
    else
        log_info "No CORS issues detected"
    fi
    
    return 0
}

# ------------------------------------------------------------------------------
# run_crlf_detection()
# Detect CRLF Injection vulnerabilities
# Arguments: $1 = Input file (URLs), $2 = Output file
# ------------------------------------------------------------------------------
run_crlf_detection() {
    local input_file="$1"
    local output_file="$2"
    
    log_info "Checking for CRLF Injection..."
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        return 1
    fi
    
    # CRLF payloads
    local crlf_payloads=(
        "%0d%0aX-Injected: header"
        "%0aX-Injected: header"
        "%0d%0a%0d%0a<script>alert(1)</script>"
        "%E5%98%8A%E5%98%8DX-Injected: header"
    )
    
    local found=0
    
    while IFS= read -r url; do
        [ -z "$url" ] && continue
        
        for payload in "${crlf_payloads[@]}"; do
            local test_url="${url}${payload}"
            
            local response
            response=$(curl -s -I --max-time 10 "$test_url" 2>/dev/null)
            
            if echo "$response" | grep -qi "X-Injected"; then
                echo "[CRLF] $test_url" >> "$output_file"
                echo -e "\033[0;31m[HIGH]\033[0m CRLF Injection: $url"
                found=$((found + 1))
                increment_finding "high"
                break
            fi
        done
        
        [ "${IS_WAF:-false}" = "true" ] && sleep 1 || sleep 0.2
        
    done < <(head -50 "$input_file")
    
    if [ "$found" -gt 0 ]; then
        log_warn "Found $found CRLF Injection vulnerabilities"
        notify_finding "HIGH" "CRLF Injection" "$found endpoints" "CRLF detection" 2>/dev/null &
    else
        log_info "No CRLF Injection detected"
    fi
    
    return 0
}

# ------------------------------------------------------------------------------
# run_header_injection_check()
# Check for various header injection issues
# Arguments: $1 = Input file (live hosts), $2 = Output file
# ------------------------------------------------------------------------------
run_header_injection_check() {
    local input_file="$1"
    local output_file="$2"
    
    log_info "Checking for header security issues..."
    
    if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
        return 1
    fi
    
    local issues=0
    
    while IFS= read -r url; do
        [ -z "$url" ] && continue
        
        local headers
        headers=$(curl -s -I --max-time 10 "$url" 2>/dev/null)
        
        # Check for missing security headers
        local missing=""
        
        if ! echo "$headers" | grep -qi "X-Frame-Options"; then
            missing="$missing X-Frame-Options"
        fi
        
        if ! echo "$headers" | grep -qi "X-Content-Type-Options"; then
            missing="$missing X-Content-Type-Options"
        fi
        
        if ! echo "$headers" | grep -qi "Content-Security-Policy"; then
            missing="$missing CSP"
        fi
        
        if ! echo "$headers" | grep -qi "Strict-Transport-Security"; then
            missing="$missing HSTS"
        fi
        
        if [ -n "$missing" ]; then
            echo "[HEADERS] $url - Missing:$missing" >> "$output_file"
            issues=$((issues + 1))
        fi
        
        # Check for information disclosure
        if echo "$headers" | grep -qiE "(X-Powered-By|Server:.*[0-9])"; then
            echo "[INFO-DISCLOSURE] $url" >> "$output_file"
            increment_finding "info"
        fi
        
    done < <(head -30 "$input_file")
    
    log_info "Checked headers on $(head -30 "$input_file" | wc -l | tr -d ' ') hosts"
    return 0
}

# ------------------------------------------------------------------------------
# run_vulnerability_scan()
# Main vulnerability scanning function
# Arguments: $1 = Workspace directory
# Returns: 0 on success, 1 on failure
# ------------------------------------------------------------------------------
run_vulnerability_scan() {
    local workspace="$1"
    
    print_section "Starting Vulnerability Scanning Phase"
    log_info "Workspace: $workspace"
    
    # Reset counters
    reset_finding_counts
    
    # Create findings directory
    local findings_dir="$workspace/findings"
    mkdir -p "$findings_dir"
    
    # Verify prerequisites
    local live_hosts="$workspace/live_hosts.txt"
    local param_urls="$workspace/params/urls_with_params.txt"
    
    # Step 1: Nuclei scan against live hosts
    if [ -f "$live_hosts" ] && [ -s "$live_hosts" ]; then
        run_nuclei_scan "$live_hosts" "$findings_dir/nuclei_results.txt"
    else
        log_warn "No live hosts found - skipping Nuclei scan"
    fi
    
    # Step 2: XSS scanning on parameterized URLs
    if [ -f "$param_urls" ] && [ -s "$param_urls" ]; then
        run_dalfox_scan "$param_urls" "$findings_dir/xss_results.txt"
    else
        log_warn "No parameterized URLs found - skipping XSS scan"
    fi
    
    # Step 3: SQLi detection
    if [ -f "$param_urls" ] && [ -s "$param_urls" ]; then
        run_sqli_detection "$param_urls" "$findings_dir/sqli_results.txt"
    else
        log_warn "No parameterized URLs found - skipping SQLi scan"
    fi
    
    # Step 4: SSRF detection
    if [ -f "$param_urls" ] && [ -s "$param_urls" ]; then
        run_ssrf_detection "$param_urls" "$findings_dir/ssrf_results.txt"
    fi
    
    # Step 5: Open Redirect detection  
    if [ -f "$param_urls" ] && [ -s "$param_urls" ]; then
        run_open_redirect_detection "$param_urls" "$findings_dir/redirect_results.txt"
    fi
    
    # Step 6: CORS misconfiguration check
    if [ -f "$live_hosts" ] && [ -s "$live_hosts" ]; then
        run_cors_check "$live_hosts" "$findings_dir/cors_results.txt"
    fi
    
    # Step 7: CRLF Injection detection
    if [ -f "$live_hosts" ] && [ -s "$live_hosts" ]; then
        run_crlf_detection "$live_hosts" "$findings_dir/crlf_results.txt"
    fi
    
    # Step 8: Header security check
    if [ -f "$live_hosts" ] && [ -s "$live_hosts" ]; then
        run_header_injection_check "$live_hosts" "$findings_dir/headers_results.txt"
    fi
    
    # Step 9: Deduplicate findings
    deduplicate_findings "$findings_dir"
    
    # Step 10: Generate report
    generate_vuln_report "$workspace"
    
    # Summary
    print_section "Vulnerability Scan Complete"
    
    # Calculate totals
    local total_critical="${FINDING_COUNTS[critical]:-0}"
    local total_high="${FINDING_COUNTS[high]:-0}"
    local total_medium="${FINDING_COUNTS[medium]:-0}"
    local total_low="${FINDING_COUNTS[low]:-0}"
    
    if [ "$total_critical" -gt 0 ]; then
        echo -e "\033[1;31m[CRITICAL] $total_critical critical findings!\033[0m"
    fi
    if [ "$total_high" -gt 0 ]; then
        echo -e "\033[0;31m[HIGH] $total_high high severity findings\033[0m"
    fi
    if [ "$total_medium" -gt 0 ]; then
        echo -e "\033[0;33m[MEDIUM] $total_medium medium severity findings\033[0m"
    fi
    if [ "$total_low" -gt 0 ]; then
        echo -e "\033[0;34m[LOW] $total_low low severity findings\033[0m"
    fi
    
    # Send completion notification
    local summary="Critical: $total_critical | High: $total_high | Medium: $total_medium | Low: $total_low"
    notify_scan_complete "${TARGET_DOMAIN:-Unknown}" "$summary" 2>/dev/null || true
    
    return 0
}

# ------------------------------------------------------------------------------
# If run directly (not sourced), show usage
# ------------------------------------------------------------------------------
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    echo "GHOST-FRAMEWORK Vulnerability Module"
    echo "Usage: source vulnerability.sh && run_vulnerability_scan <workspace>"
    echo ""
    echo "This module should be sourced from ghost.sh"
    echo "Requires: live_hosts.txt and params/ directory from previous phases"
fi
